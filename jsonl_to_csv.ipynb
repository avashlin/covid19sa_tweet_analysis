{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting .jsonl to .csv\n",
    "\n",
    "This notebook will take the .jsonl file of tweets and convert it to .csv to make the data easier to work with. \n",
    "\n",
    "I have pulled tweets from two twitter accounts with the use of Twarc to build the tweet corpora. Additionally the csv of each account will only store tweets relevant to the COVID-19 outbreak. \n",
    "\n",
    "The two twitter accounts: \n",
    "\n",
    "@Health_ZA : started reporting on COVID-19 on 25th Jan 2020. \n",
    "\n",
    "@nicd_sa: started reporting on COVID-19 on 15th Jan 2020. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Relevant Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path and file name setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name_health = \"Updated_1_healthza_tweets.jsonl\"\n",
    "input_name_nicd = \"Updated_1_nicd_tweets.jsonl\"\n",
    "unsliced_output_name_health = \"unsliced_health_za_tweets\"\n",
    "unsliced_output_name_nicd = \"unsliced_nicd_sa_tweets\"\n",
    "sliced_output_name_health = \"sliced_health_za_tweets.csv\"\n",
    "sliced_output_name_nicd = \"sliced_nicd_sa_tweets.csv\"\n",
    "\n",
    "startDateHealth = \"2020-01-27 15:21:18+00:00\"\n",
    "startDateNICD = \"2020-01-15 10:00:08+00:00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "### Convert .jsonl to .csv\n",
    "The code block below converts the jsonl to csv: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d_obj):\n",
    "\n",
    "    for k, v in d_obj.items():\n",
    "\n",
    "        if isinstance(v, dict):\n",
    "\n",
    "            new_dict = {'{}/{}'.format(k,k2):v2 for k2, v2 in v.items()}\n",
    "            yield from flatten_dict(new_dict)\n",
    "\n",
    "        else:\n",
    "            yield k, v\n",
    "\n",
    "def convertToCSV(inputname, unslicedoutputname):\n",
    "    dict_list = []\n",
    "\n",
    "    with open(inputname) as f:\n",
    "        for line in f:\n",
    "            j_data = json.loads(line)\n",
    "            new_dict = {k:v for k,v in flatten_dict(j_data)}\n",
    "            dict_list.append(new_dict)\n",
    "\n",
    "    # Write new raw JSON file with combined data\n",
    "    with open(unslicedoutputname + '.json', 'w') as new_f:\n",
    "        new_f.write(json.dumps(dict_list))\n",
    "\n",
    "    # Convert list of dicts into dataframe and send to csv\n",
    "    df = pd.DataFrame(dict_list)\n",
    "    #df.to_csv('nicd_sa_tweets.csv', index=False)\n",
    "    df.to_csv(unslicedoutputname + '.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function for each twitter corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertToCSV(input_name_health, unsliced_output_name_health )\n",
    "convertToCSV(input_name_nicd, unsliced_output_name_nicd )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read created csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_health = pd.read_csv(unsliced_output_name_health + \".csv\", sep=\",\", engine='python')\n",
    "df_nicd = pd.read_csv(unsliced_output_name_nicd + \".csv\", sep=\",\", engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3204, 346)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_health.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2022, 347)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nicd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert \"created_at\" column to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_health.created_at = pd.to_datetime(df_health.created_at, errors='coerce')\n",
    "df_nicd.created_at = pd.to_datetime(df_nicd.created_at, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying data type of datetime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-03-19 20:59:19+00:00\n",
       "1   2020-03-19 20:58:53+00:00\n",
       "2   2020-03-19 19:45:29+00:00\n",
       "3   2020-03-19 18:57:11+00:00\n",
       "4   2020-03-19 17:52:58+00:00\n",
       "Name: created_at, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_health.created_at.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2020-03-19 16:41:07+00:00\n",
       "1   2020-03-19 13:17:53+00:00\n",
       "2   2020-03-19 09:40:49+00:00\n",
       "3   2020-03-19 09:40:48+00:00\n",
       "4   2020-03-19 09:40:48+00:00\n",
       "Name: created_at, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nicd.created_at.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find row where we want to slice the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Health_ZA the first tweet about COVID-19 was 2020-01-27 at 15:21. \n",
    "\n",
    "For nicd_sa the first tweet about COVID-19 was 2020-01-15 at 10:00. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindRowNum(df, startdate):\n",
    "    for i,v in enumerate(df.created_at):\n",
    "        if str(v) == startdate:\n",
    "            return i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_num_health = FindRowNum(df_health, startDateHealth)\n",
    "row_num_nicd = FindRowNum(df_nicd, startDateNICD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create clean .csv of when the COVID-19 tweets started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_health[:row_num_health].to_csv(sliced_output_name_health, index=False, header=True)\n",
    "df_nicd[:row_num_nicd].to_csv(sliced_output_name_nicd, index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
